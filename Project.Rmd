---
title: "Predicting Whether a Kickstarter Project Will Succeed Or Fail"
author: "Austin Martinez, Cameron Morefield, and Derek McFate"
output: html_document
---

```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
This report will utilize various factors from a publicly provided Kickstarter data set to determine outcomes of a potential project The idea is to allow someone with a kickstarter idea to use their potential project's data to detirmin how successful it may be. 
<br/>

# Data Gathering and cleaning
The data set used contains 378,661 entries, and each entry has 15 variables. There were 3797
entries that had N/A values somewhere in the row, which we decided to remove from the data
set. The data set also included entries that had states other than 'Success' or 'Failure', so
those entries were either condensed into the two states or dropped completely. We also derived
a kicklen collumn from the launched and deadline dates so that we had another numeric field to
work with. 
Once the data was cleaned, it was split into training and test data.

```{r}
set.seed(123)
library(cluster)
library(e1071)
dat = read.csv("https://raw.githubusercontent.com/AMartinez2/CST383-Project/master/ks-projects-201801.csv")
dat = dat[complete.cases(dat),]
levels(dat$state)[which(levels(dat$state)=="canceled")] = "failed"
dat = dat[!(dat$state=="undefined" | dat$state=="suspended" | dat$state=="live"),]
dat$state = factor(dat$state)
# Date conversion:
ldates = as.Date(dat$launched, format = "%Y-%m-%d")
ddates = as.Date(dat$deadline, format = "%Y-%m-%d")
dat$kicklen = as.numeric(ddates - ldates)
# split our data into testing and training data
tr_rows = sample(nrow(dat), 0.8 * nrow(dat))
tr_dat = dat[tr_rows,]
te_dat = dat[-tr_rows,]
```

# Initial Exploration and visualization

```{r}
#goal
medgoal = median(dat$goal)
n_success = nrow(dat[dat$state == "successful",])
under_med_goal_success = nrow(dat[dat$goal <= medgoal & dat$state == "successful",])/n_success
over_med_goal_success = nrow(dat[dat$goal > medgoal & dat$state == "successful",])/n_success
a = c(under_med_goal_success,over_med_goal_success)

#length
medlen = median(dat$kicklen)
under_med_len_success = nrow(dat[dat$kicklen < medlen & dat$state == "successful",])/n_success
over_med_len_success = nrow(dat[dat$kicklen > medlen & dat$state == "successful",])/n_success
under_med_len_success
over_med_len_success

barplot(a)
```

# First model (Naive Bayes)

For our first model, we dicided to use Naive Bayes using only one predictor. This simple model yields roughly 66% percent accuracy and only guesses if a project will succeed or fail.

```{r}
fit = naiveBayes(state ~ category, data=tr_dat)
predicts = predict(fit, newdata=te_dat)
conf_mtx = table(predicts, te_dat$state)
conf_mtx
mean(predicts == te_dat$state)
```

# Second Model 

With our second model we can predict both the probability that a project will succeed as well as simply guess wether it will or not. First we build our logistic regression model using [insert final options here]. With this, we can make predictions on the probability of success. 

```{r}
fit = glm(state ~ category + goal + kicklen, data=tr_dat, family=binomial)
y = predict(fit, newdata=te_dat, type="response")
plot(density(y), main="Density of Predictions")
```

From our probability predictions, we can choose a threshold to detirmin succeed or fail. We will do so by iterating though the options from 0 to 1 and looking at the resulting accuracies. From there, we get our highest accuracy around 6. 

```{r}
acc = c()
actuals = te_dat$state
#conf_mtx = table(predicts, actuals)
for (i in 0:10) {
  predicts = ifelse(y > i/10, "successful", "failed")
  acc = c(acc, mean(predicts == actuals))
}
plot(acc, type="l", col="red", main="Accuracy per Threshold")
```

# Conclusion

