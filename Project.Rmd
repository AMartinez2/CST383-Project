---
title: "Predicting Whether a Kickstarter Project Will Succeed Or Fail"
author: "Austin Martinez, Cameron Morefield, and Derek McFate"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction
This report will utilize various factors from a publicly provided Kickstarter data set to determine the likelihood that a project will success or fail.
<br/>
# Data Gathering and cleaning
The data set used contains 378,661 entries, and each entry has 15 variables. There were 3797 entries that had N/A values somewhere in the row, which we decided to remove from the data set. The data set also included entries that had states other than 'Success' or 'Failure', so those entries were either condensed into the two states or dropped completely.
Once the data was cleaned, it was split into training and test data.
```{r}
set.seed(123)
library(cluster)
library(e1071)
dat = read.csv("https://raw.githubusercontent.com/AMartinez2/CST383-Project/master/ks-projects-201801.csv")
dat = dat[complete.cases(dat),]
levels(dat$state)[which(levels(dat$state)=="canceled")] = "failed"
dat = dat[!(dat$state=="undefined" | dat$state=="suspended" | dat$state=="live"),]
dat$state = factor(dat$state)
# Date conversion:
ldates = as.Date(dat$launched, format = "%Y-%m-%d")
ddates = as.Date(dat$deadline, format = "%Y-%m-%d")
dat$kicklen = as.numeric(ddates - ldates)
# split our data into testing and training data
tr_rows = sample(nrow(dat), 0.8 * nrow(dat))
tr_dat = dat[tr_rows,]
te_dat = dat[-tr_rows,]
```

# Initial Exploration and visualization

Perhaps the goal for the project influences how people will look at project which would affect if they choose to contribute. If we look at the density of goal for projects that passed (in green) and failed (in red), we can see that values align well within the same curve. The goal of the project does not seem to affect wether it passes or fails. 

```{r}
pass = dat[dat$state == "successful",]
fail = dat[dat$state == "failed",]
plot(density(pass$goal), xlim=c(0,100000), col='green', main='Double Density of Goal')
lines(density(fail$goal), col='red')
```

######### We might want to remove this ##############
```{r}
par(mar=c(3,6,1,4))
pass = dat[dat$state == "successful",]
fail = dat[dat$state == "failed",]
test2 <- rbind(table(pass$main_category),table(fail$main_category))
barplot(test2,beside=T, col=c('green','red'), horiz=TRUE, las=1)
```

```{r}
#goal
medgoal = median(dat$goal)
n_success = nrow(dat[dat$state == "successful",])
n_size = nrow(dat)
under_med_goal_success = nrow(dat[dat$goal <= medgoal & dat$state == "successful",])/n_success
over_med_goal_success = nrow(dat[dat$goal > medgoal & dat$state == "successful",])/n_success
goalvec = c(under_med_goal_success,over_med_goal_success)
a
#length
medlen = median(dat$kicklen)
funder_med_len_success = nrow(dat[dat$kicklen <= medlen & dat$state == "successful",])/n_success
tunder_med_len_success = nrow(dat[dat$kicklen < medlen & dat$state == "successful",])/n_success
over_med_len_success = nrow(dat[dat$kicklen > medlen & dat$state == "successful",])/n_success
true_med_len_success = nrow(dat[dat$kicklen == medlen & dat$state == "successful",])/n_success
tunder_med_len_success
over_med_len_success
true_med_len_success
lenvecf = c(funder_med_len_success, over_med_len_success)
lenvect = c(tunder_med_len_success, true_med_len_success, over_med_len_success)
comb = c(goalvec, lenvecf)
par(mfrow = c(2,1))
barplot(comb, beside = TRUE, ylim = c(0, 1), col = c("green", "red"), main = "Analysis of available Numeric variables", names.arg = c("Goal1", "", "Length", ""),legend.text=c('Below or at Median','Above Median'), args.legend=list(text.col=c("green", "red"),bty='n'))
```
This was a method we used to see if any of our numeric data had value for our predictions. This graph plots the percentage of successes above and below a median predictor value, in this case, the Goal Amount (USD) and the length of the Kickstarter (# of days). If the percentage for a predictor is heavily weighted one way or another (difference is large), it may indicate that the predictor has some relationship with the success/fail result. A bar graph pairing that is nearer to 50/50 shows a weaker or no relationship.

This method of determining predictors is good when a predictor has a generally even distribution of numbers, but can be less accurate with more clumped data.

# First model (Naive Bayes)
```{r}
fit = naiveBayes(state ~ category, data=tr_dat)
predicts = predict(fit, newdata=te_dat)
conf_mtx = table(predicts, te_dat$state)
conf_mtx[c('failed','successful'),c('failed','successful')]
mean(predicts == te_dat$state)
```

```{r}
library(rpart)

fit = rpart(state ~ goal, data = tr_dat)
predicted = predict(fit, te_dat, type="class")
actual = te_dat$state
table(actual, predicted)
mean(actual == predicted)
```

# Second Model 

```{r}
fit = glm(state ~ main_category + goal, data=tr_dat, family=binomial)
y = predict(fit, newdata=te_dat, type="response")
predicts = ifelse(y > 0.5, "successful", "failed")
actuals = te_dat$state
conf_mtx = table(predicts, actuals)
conf_mtx
mean(predicts == actuals)
```

```{r}

```

# Conclusion

